{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML corpus\n",
    "\n",
    "We import the Pāli Canon from the Digital Pāli Reader. The files are in Extensible Markup Language ([XML](https://en.wikipedia.org/wiki/XML)) format.\n",
    "\n",
    "- Number of XML files:  162\n",
    "- Number of characters in the whole Tipiṭaka:  90,083,712\n",
    "\n",
    "The file names give indication of their content. \n",
    "\n",
    "1. The first character of the file name:\n",
    "    - Vinaya\n",
    "        - v\n",
    "    - Sutta\n",
    "        - d\n",
    "        - m\n",
    "        - s\n",
    "        - a\n",
    "        - k\n",
    "    - Abhidhamma\n",
    "        - x\n",
    "1. The last character of the file name: \n",
    "    - `m` stands for *mūla*\n",
    "    - `a` for *athakathā*\n",
    "    - `t` for *tīkā*.\n",
    "\n",
    "Finally we remove the XML markup and produce a plain-text version of the corpus. This is written to the file `corpustextonly.txt`. (Found in the same directory as this Jupyter Notebook file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n",
      "['a10a.xml', 'a10m.xml', 'a10t.xml', 'a11a.xml', 'a11m.xml', 'a11t.xml', 'a1a.xml', 'a1m.xml', 'a1t.xml', 'a2a.xml', 'a2m.xml', 'a2t.xml', 'a3a.xml', 'a3m.xml', 'a3t.xml', 'a4a.xml', 'a4m.xml', 'a4t.xml', 'a5a.xml', 'a5m.xml', 'a5t.xml', 'a6a.xml', 'a6m.xml', 'a6t.xml', 'a7a.xml', 'a7m.xml', 'a7t.xml', 'a8a.xml', 'a8m.xml', 'a8t.xml', 'a9a.xml', 'a9m.xml', 'a9t.xml', 'b1m.xml', 'b2m.xml', 'd1a.xml', 'd1m.xml', 'd1t.xml', 'd2a.xml', 'd2m.xml', 'd2t.xml', 'd3a.xml', 'd3m.xml', 'd3t.xml', 'g1m.xml', 'g2m.xml', 'g3m.xml', 'g4m.xml', 'g5m.xml', 'k10a.xml', 'k10m.xml', 'k11m.xml', 'k12a.xml', 'k12m.xml', 'k13a.xml', 'k13m.xml', 'k14a.xml', 'k14m.xml', 'k15a.xml', 'k15m.xml', 'k16m.xml', 'k17m.xml', 'k18m.xml', 'k19m.xml', 'k1a.xml', 'k1m.xml', 'k20m.xml', 'k21m.xml', 'k2a.xml', 'k2m.xml', 'k3a.xml', 'k3m.xml', 'k4a.xml', 'k4m.xml', 'k5a.xml', 'k5m.xml', 'k6a.xml', 'k6m.xml', 'k7a.xml', 'k7m.xml', 'k8a.xml', 'k8m.xml', 'k9a.xml', 'k9m.xml', 'm1a.xml', 'm1m.xml', 'm1t.xml', 'm2a.xml', 'm2m.xml', 'm2t.xml', 'm3a.xml', 'm3m.xml', 'm3t.xml', 's1a.xml', 's1m.xml', 's1t.xml', 's2a.xml', 's2m.xml', 's2t.xml', 's3a.xml', 's3m.xml', 's3t.xml', 's4a.xml', 's4m.xml', 's4t.xml', 's5a.xml', 's5m.xml', 's5t.xml', 'v10t.xml', 'v1a.xml', 'v1m.xml', 'v1t.xml', 'v2a.xml', 'v2m.xml', 'v2t.xml', 'v3a.xml', 'v3m.xml', 'v3t.xml', 'v4a.xml', 'v4m.xml', 'v4t.xml', 'v5a.xml', 'v5m.xml', 'v5t.xml', 'v6a.xml', 'v6m.xml', 'v6t.xml', 'v7t.xml', 'v8t.xml', 'v9t.xml', 'x1a.xml', 'x1m.xml', 'x2a.xml', 'x2m.xml', 'y10m.xml', 'y11m.xml', 'y12m.xml', 'y13m.xml', 'y14m.xml', 'y1a.xml', 'y1m.xml', 'y1t.xml', 'y2a.xml', 'y2m.xml', 'y2t.xml', 'y3a.xml', 'y3m.xml', 'y3t.xml', 'y4a.xml', 'y4m.xml', 'y4t.xml', 'y5a.xml', 'y5m.xml', 'y5t.xml', 'y6a.xml', 'y6m.xml', 'y6t.xml', 'y7m.xml', 'y8m.xml', 'y9a.xml', 'y9m.xml', 'y9t.xml']\n",
      "Number of XML files:  162\n",
      "Number of characters in the whole Tipiṭaka:  90083712\n"
     ]
    }
   ],
   "source": [
    "%pprint\n",
    "import nltk, os, matplotlib\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "\n",
    "# list of xml files\n",
    "\n",
    "fileids = os.listdir(\"..\")\n",
    "fileids = [f for f in fileids if len(f) < 9 and 'xml' in f ]\n",
    "print(fileids)\n",
    "print(\"Number of XML files: \", len(fileids))\n",
    "raw = ''\n",
    "c = open('corpusinxml.txt','w')\n",
    "for fileid in fileids:\n",
    "    f = open(\"../\" + fileid)\n",
    "    for line in f:\n",
    "        raw += line\n",
    "        c.write(line)\n",
    "c.close()\n",
    "print(\"Number of characters in the whole Tipiṭaka: \", len(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('corpusinxml.txt')\n",
    "raw = f.read()\n",
    "raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "c = open('corpustextonly.txt','w')\n",
    "c.write(raw2)\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text only corpus\n",
    "\n",
    "The next step is to tokenize our corpus, that is to break up a single long string into a list of words. The lexer we use is the built-in word tokenizer of the NLTK toolkit.\n",
    "\n",
    "After cleaning away manuscript variations and non-alphanumeric words we produce a list of tokens. This process is considered a sub-task of parsing.\n",
    "\n",
    "We list the most common collocations of the text, followed by the 50 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['namo',\n",
       " 'tassa',\n",
       " 'bhagavato',\n",
       " 'arahato',\n",
       " 'aṅguttaranikāye',\n",
       " 'paṭhamapaṇṇāsakaṃ',\n",
       " 'ānisaṃsavaggo',\n",
       " 'kimatthiyasuttavaṇṇanā',\n",
       " 'dasakanipātassa',\n",
       " 'paṭhame',\n",
       " 'anavajjasīlāni',\n",
       " 'amaṅkubhāvassa',\n",
       " 'avippaṭisārassa',\n",
       " 'atthāya',\n",
       " 'saṃvattantīti',\n",
       " 'so',\n",
       " 'nesaṃ',\n",
       " 'ānisaṃsoti',\n",
       " 'nāma',\n",
       " 'taruṇavipassanā',\n",
       " 'nāma',\n",
       " 'balavavipassanā',\n",
       " 'nāma',\n",
       " 'maggo',\n",
       " 'nāma',\n",
       " 'arahattaphalaṃ',\n",
       " 'nāma',\n",
       " 'paccavekkhaṇañāṇaṃ',\n",
       " 'arahattatthāya',\n",
       " 'gacchanti',\n",
       " 'cetanākaraṇīyasuttavaṇṇanā',\n",
       " 'dutiye',\n",
       " 'cetanāya',\n",
       " 'na',\n",
       " 'cetetvā',\n",
       " 'kappetvā',\n",
       " 'pakappetvā',\n",
       " 'kātabbaṃ',\n",
       " 'dhammasabhāvo',\n",
       " 'eso',\n",
       " 'kāraṇaniyamo',\n",
       " 'ayaṃ',\n",
       " 'pavattenti',\n",
       " 'paripuṇṇaṃ',\n",
       " 'karonti',\n",
       " 'pāraṃ',\n",
       " 'orimatīrabhūtā',\n",
       " 'tebhūmakavaṭṭā',\n",
       " 'nibbānapāraṃ',\n",
       " 'gamanatthāya']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "f = open('corpustextonly.txt', 'r')\n",
    "raw3 = f.read()\n",
    "tokens = word_tokenize(raw3)\n",
    "tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhammaṃ paṭicca; dhammo uppajjati; uppajjati hetupaccayā; atha kho;\n",
      "hevaṃ vattabbe; eseva nayo; tasmiṃ samaye; kho bhikkhave; tesaṃ\n",
      "tattha; ārammaṇapaccayena paccayo; āpatti dukkaṭassa; tenupasaṅkami\n",
      "upasaṅkamitvā; paraṃ maraṇā; puna caparaṃ; upanissayapaccayena\n",
      "paccayo; kāyassa bhedā; dhammassa ārammaṇapaccayena; kha yassa; pana\n",
      "samayena; atha naṃ\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', 124664),\n",
       " ('na', 115997),\n",
       " ('ti', 100631),\n",
       " ('vā', 86685),\n",
       " ('hoti', 56120),\n",
       " ('pana', 55227),\n",
       " ('taṃ', 48846),\n",
       " ('tattha', 42965),\n",
       " ('kho', 42961),\n",
       " ('evaṃ', 41307),\n",
       " ('so', 39691),\n",
       " ('bhikkhave', 32747),\n",
       " ('nāma', 32175),\n",
       " ('te', 31782),\n",
       " ('tassa', 29663),\n",
       " ('hi', 28832),\n",
       " ('vuttaṃ', 23984),\n",
       " ('nti', 22969),\n",
       " ('attho', 20175),\n",
       " ('ayaṃ', 20132),\n",
       " ('tena', 19863),\n",
       " ('viya', 19721),\n",
       " ('me', 19462),\n",
       " ('tesaṃ', 19068),\n",
       " ('atha', 18408),\n",
       " ('dhammaṃ', 17971),\n",
       " ('bhagavā', 17081),\n",
       " ('dhammo', 16889),\n",
       " ('uppajjati', 16857),\n",
       " ('katvā', 16826),\n",
       " ('paccayo', 16463),\n",
       " ('dhammā', 16308),\n",
       " ('yaṃ', 15895),\n",
       " ('ekaṃ', 15311),\n",
       " ('āha', 15143),\n",
       " ('idaṃ', 15058),\n",
       " ('paṭicca', 14963),\n",
       " ('yathā', 14905),\n",
       " ('no', 14823),\n",
       " ('bhante', 14781),\n",
       " ('tasmā', 14600),\n",
       " ('bhikkhu', 13841),\n",
       " ('tato', 13812),\n",
       " ('attano', 13470),\n",
       " ('dve', 13458),\n",
       " ('yo', 13386),\n",
       " ('ettha', 12278),\n",
       " ('tathā', 11925),\n",
       " ('tīṇi', 11289),\n",
       " ('atthi', 11206)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(text)\n",
    "fd.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent 1,000\n",
    "\n",
    "Kurt Schmidt published a book that consists of the 1,000 most frequent Pāli words: [Frequency Dictionary of Pāli: Core Vocabulary for Learners](https://www.amazon.com/Frequency-Dictionary-Pali-Vocabulary-Learners/dp/1478369159).\n",
    "\n",
    "We can do the same below in three lines of code. The list can be found in the file `most_common_1000.txt` in the same directory as this file. (Instant publishing, just add water.)\n",
    "\n",
    "Note the error in Schmidt's title. p.416 the first page in the index of words shows already that his list takes as separate entries different tokens of the same vocabulary item. For example each of the following pairs are given as their own `\"vocabulary\"` items.\n",
    "\n",
    "https://www.dropbox.com/s/afa79kkw4yz1bsb/Screenshot%202017-11-28%2016.53.21.png?dl=0\n",
    "\n",
    "- aham\n",
    "- ahampi\n",
    "\n",
    "\n",
    "- aññataraṃ\n",
    "- aññattaro\n",
    "\n",
    "\n",
    "This is a mistake in the type-token distinction. It would have been better to title his book Most Frequent Surface Forms (Tokens). To be counted as vocabulary we would only count the word types, but not each word as a separate entry. I will talk more about this in the stemming/lemmatization section.\n",
    "\n",
    "(#todo: compare Schmidt's list with mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('most_common_1000.txt','w') as mc:\n",
    "    for token in fd.most_common(1000):\n",
    "        mc.write(str(token[0] + \" \" + str(token[1]) + \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rare form of personal pronoun\n",
    "\n",
    "Warder (needs citation) lists *asmākam* as a rare form of *amhākam* the genitive of the first person singular pronoun. We now have a tool to take a look at the frequency distribution of these two forms.\n",
    "\n",
    "|form|frequency|probability|\n",
    "|-----|---------|----------|\n",
    "|amhākaṃ | 3271 |  99.42% |\n",
    "|asmākaṃ | 19 |     0.58%  |\n",
    "| **total**| **3290** |   **100%** |\n",
    "\n",
    "We find that indeed asmākaṃ is about 17 times less frequent.\n",
    "\n",
    "Note 1: This approach does not take into account any forms with sandhi where the initial `a` may have been omitted such as 'mhākaṃ, 'smākaṃ. (#todo)\n",
    "\n",
    "Note 2: It would be interesting to see exactly where the 19 occurrences of asmākaṃ come from and whether there is some shared property among them e.g. author, or era. (#todo ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 3271 matches:\n",
      "sa gotamassa dhammadesanāya saddhiṃ amhākaṃ dhammadesanaṃ amhākaṃ vā dhammadesa\n",
      "anāya saddhiṃ amhākaṃ dhammadesanaṃ amhākaṃ vā dhammadesanāya saddhiṃ samaṇassa\n",
      "cetiyaṃ pūjimhā ti kathetuṃ vaṭṭati amhākaṃ ñātakā sūrā samatthā ti vā pubbe ma\n",
      " bhikkhuno kālakato pitā vā mātā vā amhākaṃ ñātakatthero sīlavā kalyāṇadhammo t\n",
      "māsi therā disvāva ime paccayā neva amhākaṃ na kokālikassa kappantī ti paṭikkhi\n",
      "o atthaṃ nīharitvā dassetā no yathā amhākaṃ bhagavā byākareyya ajitasuttavaṇṇan\n",
      " nānākaraṇaṃ samaṇassa vā gotamassa amhākaṃ vā yadidaṃ dhammadesanāya vā dhamma\n",
      "ṃ piṇḍāya pavisimhā tesaṃ no bhante amhākaṃ etadahosi kho tāva sāvatthiyaṃ piṇḍ\n",
      " nānākaraṇaṃ samaṇassa vā gotamassa amhākaṃ vā yadidaṃ dhammadesanāya vā dhamma\n",
      "aṃ paviṭṭho ca tathā tesaṃ no āvuso amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "sa vitthārena atthaṃ tesaṃ no āvuso amhākaṃ etadahosi kho āyasmā ānando satthu \n",
      "ave veditabbo tathā tesaṃ no bhante amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "a vitthārena atthaṃ tesaṃ no bhante amhākaṃ etadahosi kho āyasmā ānando satthu \n",
      "o paribbājako bhagavantaṃ etadavoca amhākaṃ bho gotama paṇḍito nāma sabrahmacār\n",
      "mo yathā attho tathā tesaṃ no āvuso amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "sa vitthārena atthaṃ tesaṃ no āvuso amhākaṃ etadahosi kho āyasmā mahākaccāno sa\n",
      "ave veditabbo tathā tesaṃ no bhante amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "a vitthārena atthaṃ tesaṃ no bhante amhākaṃ etadahosi kho āyasmā mahākaccāno sa\n",
      "ke nigame pubbe kira jā aṭṭha ādayo amhākaṃ bodhisatto kapiyoniyaṃ nibbatto mah\n",
      "baddho eko vihāro nāma natthi tasmā amhākaṃ anibaddhavihārena viharantānaṃ kena\n",
      "i gosāmikā disvā ayaṃ ettakaṃ kālaṃ amhākaṃ dhenū duhī ti tajjetvā attano gāviy\n",
      "atha naṃ sabbahatthino sannipatitvā amhākaṃ verī ti vicuṇṇayiṃsu evaṃ tāva itth\n",
      "hehi saddhiṃ bhikkhusaṅgho gacchatu amhākaṃ asukatthero anumodanaṃ karissatī ti\n",
      "gatosi paṭisāmehīti subbaco bhikkhu amhākaṃ ācariyo ajānitvā evaṃ na vakkhatī t\n",
      "so cintesi atthi nu kho idaṃ sukhaṃ amhākaṃ ācariyassā ti so āvajjento therassa\n"
     ]
    }
   ],
   "source": [
    "text.concordance('amhākaṃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 19 of 19 matches:\n",
      "ppavedite ayaṃ kho panāvuso amhākaṃ asmākaṃ bhagavatā bhagavato dhammo svākkhāt\n",
      "aṃmamaṃ naṃsesvamussa savibhattissa asmākaṃ mamaṃ honti vā yathākkamaṃ asmākaṃ \n",
      " asmākaṃ mamaṃ honti vā yathākkamaṃ asmākaṃ amhākaṃ mamaṃ mama simhi amhassa sa\n",
      "i amhebhi mayhaṃ mama amhaṃ amhākaṃ asmākaṃ mayā amhehi amhebhi mayhaṃ mama amh\n",
      "i amhebhi mayhaṃ mama amhaṃ amhākaṃ asmākaṃ mayi amhesu asmesu ettha pana katha\n",
      "smiṃ vuttā ayañhi suddhakattuvisaye asmākaṃ ruci sukhatīti sukhito dukkhatīti d\n",
      "akārena pāḷiyo paṭibhanti no tattha asmākaṃ khantiyā dajjā dajja ntiādīni satta\n",
      "i tesaṃ doso hotīti na hoti suṇātha asmākaṃ sodhanaṃ tathā hi aṭṭhakathācariyeh\n",
      "kvaci tumhaṃ tumhākaṃ amhaṃ amhākaṃ asmākaṃ vā pañcamiyaṃ amhatumhanturāja iccā\n",
      "ggaho tumhaṃ tumhākaṃ amhaṃ amhākaṃ asmākaṃ dhammatā smiṃmhī ti vattate sabbesa\n",
      " puriso nāma dullabho tena kāraṇena asmākaṃ evarūpesu ṭhānesu adhivāsanakhantiy\n",
      "ṃ kumāro kathessatī ti vadati nāyaṃ asmākaṃ ruccati ettha nipātamattaṃ vidhuro \n",
      "ā ñātisaṅghassa mantaraṃ adassanena asmākaṃ dukkhaṃ bahūsu tesaṃ sokavighātāya \n",
      "bhāyāmi sumukha sāmāya lakkhaṇūruyā asmākaṃ vadhamaññāya athattānaṃ pākahaṃsā c\n",
      "itāva puttānaṃ bhūtānaṃ dharaṇīriva asmākaṃ adhipannānaṃ khamassu rājakuñjarā t\n",
      "ā ñātisaṅghassa mantaraṃ adassanena asmākaṃ amhākaṃ dukkhaṃ bahūsu tesaṃ sokavi\n",
      "bhāyāmi sumukha sāmāya lakkhaṇūruyā asmākaṃ vadhamaññāya athattānaṃ pākahaṃsā c\n",
      "itāva puttānaṃ bhūtānaṃ dharaṇīriva asmākaṃ adhipannānaṃ khamassu rājakuñjara e\n",
      "nasaṇḍaṃ anuppattā ayuttaṃ kho pana asmākaṃ ayyesu idha vasantesu puttadāre gah\n"
     ]
    }
   ],
   "source": [
    "text.concordance('asmākaṃ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic statistics of the Tipiṭaka\n",
    "\n",
    "The three 'baskets' of the Buddhist Canon are Vinaya, Sutta, and Abhidhamma. We will now take the *mūla* files of each basket and list below how many tokens each contain (that is how many words long they are in total).\n",
    "\n",
    "\n",
    "| basket  | #files | #tokens |\n",
    "|---------|--------|---------|\n",
    "|Vinaya   |    6   |  403,657|\n",
    "|Sutta    |   43   |1,534,386|\n",
    "|Abhidamma|    2   |  114,368|\n",
    "|**total**|   51   |2,052,411|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1m.xml', 'v2m.xml', 'v3m.xml', 'v4m.xml', 'v5m.xml', 'v6m.xml']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make vinaya text, mūla only\n",
    "vinaya_files=[f for f in os.listdir('..') if f[0] == 'v' and f[-5]=='m']\n",
    "vinaya_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1m.xml 69771 cumulative 0\n",
      "v2m.xml 46150 cumulative 69771\n",
      "v3m.xml 31302 cumulative 115921\n",
      "v4m.xml 100456 cumulative 147223\n",
      "v5m.xml 94064 cumulative 247679\n",
      "v6m.xml 61914 cumulative 341743\n",
      "vinaya tokens 403657\n"
     ]
    }
   ],
   "source": [
    "vinaya_tokens = []\n",
    "for fileid in vinaya_files:\n",
    "    f = open(\"../\" + fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens), 'cumulative', len(vinaya_tokens))\n",
    "    vinaya_tokens.extend(tokens)\n",
    "print('vinaya tokens', len(vinaya_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# make sutta text, mūla only\n",
    "sutta_files = [f for f in os.listdir('..') if f[0] in 'dmsak' and f[-5]=='m']\n",
    "sutta_files\n",
    "print(len(sutta_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a10m.xml 45990\n",
      "a11m.xml 8095\n",
      "a1m.xml 7530\n",
      "a2m.xml 9420\n",
      "a3m.xml 37783\n",
      "a4m.xml 48188\n",
      "a5m.xml 43596\n",
      "a6m.xml 26897\n",
      "a7m.xml 21592\n",
      "a8m.xml 29842\n",
      "a9m.xml 16757\n",
      "d1m.xml 43569\n",
      "d2m.xml 51792\n",
      "d3m.xml 43343\n",
      "k10m.xml 62048\n",
      "k11m.xml 12254\n",
      "k12m.xml 9564\n",
      "k13m.xml 3762\n",
      "k14m.xml 42057\n",
      "k15m.xml 46897\n",
      "k16m.xml 73095\n",
      "k17m.xml 48428\n",
      "k18m.xml 72520\n",
      "k19m.xml 71467\n",
      "k1m.xml 1131\n",
      "k20m.xml 28007\n",
      "k21m.xml 33035\n",
      "k2m.xml 5295\n",
      "k3m.xml 20253\n",
      "k4m.xml 11675\n",
      "k5m.xml 20119\n",
      "k6m.xml 12236\n",
      "k7m.xml 10321\n",
      "k8m.xml 15237\n",
      "k9m.xml 6004\n",
      "m1m.xml 80387\n",
      "m2m.xml 89322\n",
      "m3m.xml 69114\n",
      "s1m.xml 37052\n",
      "s2m.xml 41180\n",
      "s3m.xml 43465\n",
      "s4m.xml 65319\n",
      "s5m.xml 68748\n",
      "sutta tokens 1534386\n"
     ]
    }
   ],
   "source": [
    "sutta_tokens = []\n",
    "for fileid in sutta_files:\n",
    "    f = open(\"../\" + fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens))\n",
    "    sutta_tokens.extend(tokens)\n",
    "print('sutta tokens', len(sutta_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(set(sutta_tokens)))\n",
    "sutta_text = nltk.Text(sutta_tokens)\n",
    "sutta_text.collocations()\n",
    "fd = nltk.FreqDist(sutta_text)\n",
    "fd.most_common(50)\n",
    "fd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(fd)\n",
    "len(fd.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1m.xml', 'x2m.xml']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make abhidamma text , mūla only\n",
    "abhi_files = [f for f in os.listdir('..') if f[0] == 'x'  and f[-5]=='m']\n",
    "abhi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1m.xml 59416 cumulative 0\n",
      "x2m.xml 54952 cumulative 59416\n",
      "abhidamma tokens 114368\n"
     ]
    }
   ],
   "source": [
    "abhidhamma_tokens = []\n",
    "for fileid in abhi_files:\n",
    "    f = open(\"../\" + fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens), 'cumulative', len(abhidhamma_tokens))\n",
    "    abhidhamma_tokens.extend(tokens)\n",
    "print('abhidamma tokens', len(abhidhamma_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
