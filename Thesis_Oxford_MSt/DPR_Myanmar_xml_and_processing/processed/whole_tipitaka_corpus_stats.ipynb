{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pprint\n",
    "import nltk, os, matplotlib\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "\n",
    "# list of xml files\n",
    "\n",
    "fileids = os.listdir(\"..\")\n",
    "fileids = [f for f in fileids if len(f) < 9 and 'xml' in f ]\n",
    "print(fileids)\n",
    "raw = ''\n",
    "c = open('corpusinxml.txt','w')\n",
    "for fileid in fileids:\n",
    "    f = open(\"../\" + fileid)\n",
    "    for line in f:\n",
    "        raw += line\n",
    "        c.write(line)\n",
    "c.close()\n",
    "print(\"Number of characters in the whole Tipiṭaka: \", len(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('corpusinxml.txt')\n",
    "raw = f.read()\n",
    "raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "c = open('corpustextonly.txt','w')\n",
    "c.write(raw2)\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text only corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['namo',\n",
       " 'tassa',\n",
       " 'bhagavato',\n",
       " 'arahato',\n",
       " 'aṅguttaranikāye',\n",
       " 'paṭhamapaṇṇāsakaṃ',\n",
       " 'ānisaṃsavaggo',\n",
       " 'kimatthiyasuttavaṇṇanā',\n",
       " 'dasakanipātassa',\n",
       " 'paṭhame',\n",
       " 'anavajjasīlāni',\n",
       " 'amaṅkubhāvassa',\n",
       " 'avippaṭisārassa',\n",
       " 'atthāya',\n",
       " 'saṃvattantīti',\n",
       " 'so',\n",
       " 'nesaṃ',\n",
       " 'ānisaṃsoti',\n",
       " 'nāma',\n",
       " 'taruṇavipassanā',\n",
       " 'nāma',\n",
       " 'balavavipassanā',\n",
       " 'nāma',\n",
       " 'maggo',\n",
       " 'nāma',\n",
       " 'arahattaphalaṃ',\n",
       " 'nāma',\n",
       " 'paccavekkhaṇañāṇaṃ',\n",
       " 'arahattatthāya',\n",
       " 'gacchanti',\n",
       " 'cetanākaraṇīyasuttavaṇṇanā',\n",
       " 'dutiye',\n",
       " 'cetanāya',\n",
       " 'na',\n",
       " 'cetetvā',\n",
       " 'kappetvā',\n",
       " 'pakappetvā',\n",
       " 'kātabbaṃ',\n",
       " 'dhammasabhāvo',\n",
       " 'eso',\n",
       " 'kāraṇaniyamo',\n",
       " 'ayaṃ',\n",
       " 'pavattenti',\n",
       " 'paripuṇṇaṃ',\n",
       " 'karonti',\n",
       " 'pāraṃ',\n",
       " 'orimatīrabhūtā',\n",
       " 'tebhūmakavaṭṭā',\n",
       " 'nibbānapāraṃ',\n",
       " 'gamanatthāya']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "f = open('corpustextonly.txt', 'r')\n",
    "raw3 = f.read()\n",
    "tokens = word_tokenize(raw3)\n",
    "tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhammaṃ paṭicca; dhammo uppajjati; uppajjati hetupaccayā; atha kho;\n",
      "hevaṃ vattabbe; eseva nayo; tasmiṃ samaye; kho bhikkhave; tesaṃ\n",
      "tattha; ārammaṇapaccayena paccayo; āpatti dukkaṭassa; tenupasaṅkami\n",
      "upasaṅkamitvā; paraṃ maraṇā; puna caparaṃ; upanissayapaccayena\n",
      "paccayo; kāyassa bhedā; dhammassa ārammaṇapaccayena; kha yassa; pana\n",
      "samayena; atha naṃ\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', 124664),\n",
       " ('na', 115997),\n",
       " ('ti', 100631),\n",
       " ('vā', 86685),\n",
       " ('hoti', 56120),\n",
       " ('pana', 55227),\n",
       " ('taṃ', 48846),\n",
       " ('tattha', 42965),\n",
       " ('kho', 42961),\n",
       " ('evaṃ', 41307),\n",
       " ('so', 39691),\n",
       " ('bhikkhave', 32747),\n",
       " ('nāma', 32175),\n",
       " ('te', 31782),\n",
       " ('tassa', 29663),\n",
       " ('hi', 28832),\n",
       " ('vuttaṃ', 23984),\n",
       " ('nti', 22969),\n",
       " ('attho', 20175),\n",
       " ('ayaṃ', 20132),\n",
       " ('tena', 19863),\n",
       " ('viya', 19721),\n",
       " ('me', 19462),\n",
       " ('tesaṃ', 19068),\n",
       " ('atha', 18408),\n",
       " ('dhammaṃ', 17971),\n",
       " ('bhagavā', 17081),\n",
       " ('dhammo', 16889),\n",
       " ('uppajjati', 16857),\n",
       " ('katvā', 16826),\n",
       " ('paccayo', 16463),\n",
       " ('dhammā', 16308),\n",
       " ('yaṃ', 15895),\n",
       " ('ekaṃ', 15311),\n",
       " ('āha', 15143),\n",
       " ('idaṃ', 15058),\n",
       " ('paṭicca', 14963),\n",
       " ('yathā', 14905),\n",
       " ('no', 14823),\n",
       " ('bhante', 14781),\n",
       " ('tasmā', 14600),\n",
       " ('bhikkhu', 13841),\n",
       " ('tato', 13812),\n",
       " ('attano', 13470),\n",
       " ('dve', 13458),\n",
       " ('yo', 13386),\n",
       " ('ettha', 12278),\n",
       " ('tathā', 11925),\n",
       " ('tīṇi', 11289),\n",
       " ('atthi', 11206)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(text)\n",
    "fd.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = open('most_common_1000.txt','w')\n",
    "for token in fd.most_common(1000):\n",
    "    mc.write(str(token[0] + \" \" + str(token[1]) + \"\\n\"))\n",
    "mc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 8792 matches:\n",
      "so tasmiṃ samaye āvuso tasmiṃ samaye ahaṃ bhavanirodho nibbāna nti imāya phala\n",
      "āmaṃ jhāyaṃ evaṃ kilesasenaṃ jinitvā ahaṃ ekakova jhāyanto sukhaṃ anubujjhiṃ s\n",
      "to bahiddhā pavattānaṃ no ca me sace ahaṃ atīte na bhavissaṃ etarahipi me ayaṃ\n",
      "taṃ upakāraṃ sandhāya kataññutaṃ kho ahaṃ bhante kataveditaṃ sampassamāno ti ā\n",
      " me atthi nu kho paṭiladdhaviseso so ahaṃ maraṇamañce nipannakāle sabrahmacārī\n",
      "natthampetaṃ vuttaṃ tatiyavāre yesaṃ ahaṃ te tesaṃ devānaṃ vā manussānaṃ vā te\n",
      "diṭṭhīnaṃ samugghātakattā taṃ sabbaṃ ahaṃ jānāmi kiṃkāraṇā ahaṃ vakkhāmi āhune\n",
      "ttā taṃ sabbaṃ ahaṃ jānāmi kiṃkāraṇā ahaṃ vakkhāmi āhuneyyasuttādivaṇṇanā satt\n",
      "ā nāma patiṭṭhaṃ labhati cāhaṃ ko ca ahaṃ ko hatthināgo ko ahampi tiracchānaga\n",
      " sacchikiriyāya saṃvattanti visārado ahaṃ ānanda tattha paṭijānāmi tesaṃ tathā\n",
      "dasa pañhā dasuddesā dasa imassa kho ahaṃ āvuso bhagavatā saṃkhittena bhāsitas\n",
      "pahāraṃ upadaṃsesī ti kataññutaṃ kho ahaṃ bhante kataveditaṃ sampassamāno bhag\n",
      "ammatāya kusaladhammatāya idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      " kusalasīlena samannāgato idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "āni senāsanāni paṭisevati idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "ccayabhesajjaparikkhārena idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "raṃ puññakkhettaṃ lokassa idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "akicchalābhī akasiralābhī idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "akicchalābhī akasiralābhī idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "ṃ pubbenivāsaṃ anussarati idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "ākammūpage satte pajānāti idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "atvā upasampajja viharati idampi kho ahaṃ bhante atthavasaṃ sampassamāno bhaga\n",
      "na abhiṇhaṃ paccavekkhitabbaṃ nu kho ahaṃ suññāgāre pabbajitena abhiṇhaṃ pacca\n",
      "mmesu pageva parihāniṃ vuḍḍhiñca kho ahaṃ bhikkhave vaṇṇayāmi kusalesu dhammes\n",
      "amasamagatikā bhavissanti evaṃ vutte ahaṃ bhante migasālaṃ upāsikaṃ etadavocaṃ\n"
     ]
    }
   ],
   "source": [
    "text.concordance('ahaṃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 3271 matches:\n",
      "sa gotamassa dhammadesanāya saddhiṃ amhākaṃ dhammadesanaṃ amhākaṃ vā dhammadesa\n",
      "anāya saddhiṃ amhākaṃ dhammadesanaṃ amhākaṃ vā dhammadesanāya saddhiṃ samaṇassa\n",
      "cetiyaṃ pūjimhā ti kathetuṃ vaṭṭati amhākaṃ ñātakā sūrā samatthā ti vā pubbe ma\n",
      " bhikkhuno kālakato pitā vā mātā vā amhākaṃ ñātakatthero sīlavā kalyāṇadhammo t\n",
      "māsi therā disvāva ime paccayā neva amhākaṃ na kokālikassa kappantī ti paṭikkhi\n",
      "o atthaṃ nīharitvā dassetā no yathā amhākaṃ bhagavā byākareyya ajitasuttavaṇṇan\n",
      " nānākaraṇaṃ samaṇassa vā gotamassa amhākaṃ vā yadidaṃ dhammadesanāya vā dhamma\n",
      "ṃ piṇḍāya pavisimhā tesaṃ no bhante amhākaṃ etadahosi kho tāva sāvatthiyaṃ piṇḍ\n",
      " nānākaraṇaṃ samaṇassa vā gotamassa amhākaṃ vā yadidaṃ dhammadesanāya vā dhamma\n",
      "aṃ paviṭṭho ca tathā tesaṃ no āvuso amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "sa vitthārena atthaṃ tesaṃ no āvuso amhākaṃ etadahosi kho āyasmā ānando satthu \n",
      "ave veditabbo tathā tesaṃ no bhante amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "a vitthārena atthaṃ tesaṃ no bhante amhākaṃ etadahosi kho āyasmā ānando satthu \n",
      "o paribbājako bhagavantaṃ etadavoca amhākaṃ bho gotama paṇḍito nāma sabrahmacār\n",
      "mo yathā attho tathā tesaṃ no āvuso amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "sa vitthārena atthaṃ tesaṃ no āvuso amhākaṃ etadahosi kho āyasmā mahākaccāno sa\n",
      "ave veditabbo tathā tesaṃ no bhante amhākaṃ acirapakkantassa bhagavato etadahos\n",
      "a vitthārena atthaṃ tesaṃ no bhante amhākaṃ etadahosi kho āyasmā mahākaccāno sa\n",
      "ke nigame pubbe kira jā aṭṭha ādayo amhākaṃ bodhisatto kapiyoniyaṃ nibbatto mah\n",
      "baddho eko vihāro nāma natthi tasmā amhākaṃ anibaddhavihārena viharantānaṃ kena\n",
      "i gosāmikā disvā ayaṃ ettakaṃ kālaṃ amhākaṃ dhenū duhī ti tajjetvā attano gāviy\n",
      "atha naṃ sabbahatthino sannipatitvā amhākaṃ verī ti vicuṇṇayiṃsu evaṃ tāva itth\n",
      "hehi saddhiṃ bhikkhusaṅgho gacchatu amhākaṃ asukatthero anumodanaṃ karissatī ti\n",
      "gatosi paṭisāmehīti subbaco bhikkhu amhākaṃ ācariyo ajānitvā evaṃ na vakkhatī t\n",
      "so cintesi atthi nu kho idaṃ sukhaṃ amhākaṃ ācariyassā ti so āvajjento therassa\n"
     ]
    }
   ],
   "source": [
    "text.concordance('amhākaṃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 19 of 19 matches:\n",
      "ppavedite ayaṃ kho panāvuso amhākaṃ asmākaṃ bhagavatā bhagavato dhammo svākkhāt\n",
      "aṃmamaṃ naṃsesvamussa savibhattissa asmākaṃ mamaṃ honti vā yathākkamaṃ asmākaṃ \n",
      " asmākaṃ mamaṃ honti vā yathākkamaṃ asmākaṃ amhākaṃ mamaṃ mama simhi amhassa sa\n",
      "i amhebhi mayhaṃ mama amhaṃ amhākaṃ asmākaṃ mayā amhehi amhebhi mayhaṃ mama amh\n",
      "i amhebhi mayhaṃ mama amhaṃ amhākaṃ asmākaṃ mayi amhesu asmesu ettha pana katha\n",
      "smiṃ vuttā ayañhi suddhakattuvisaye asmākaṃ ruci sukhatīti sukhito dukkhatīti d\n",
      "akārena pāḷiyo paṭibhanti no tattha asmākaṃ khantiyā dajjā dajja ntiādīni satta\n",
      "i tesaṃ doso hotīti na hoti suṇātha asmākaṃ sodhanaṃ tathā hi aṭṭhakathācariyeh\n",
      "kvaci tumhaṃ tumhākaṃ amhaṃ amhākaṃ asmākaṃ vā pañcamiyaṃ amhatumhanturāja iccā\n",
      "ggaho tumhaṃ tumhākaṃ amhaṃ amhākaṃ asmākaṃ dhammatā smiṃmhī ti vattate sabbesa\n",
      " puriso nāma dullabho tena kāraṇena asmākaṃ evarūpesu ṭhānesu adhivāsanakhantiy\n",
      "ṃ kumāro kathessatī ti vadati nāyaṃ asmākaṃ ruccati ettha nipātamattaṃ vidhuro \n",
      "ā ñātisaṅghassa mantaraṃ adassanena asmākaṃ dukkhaṃ bahūsu tesaṃ sokavighātāya \n",
      "bhāyāmi sumukha sāmāya lakkhaṇūruyā asmākaṃ vadhamaññāya athattānaṃ pākahaṃsā c\n",
      "itāva puttānaṃ bhūtānaṃ dharaṇīriva asmākaṃ adhipannānaṃ khamassu rājakuñjarā t\n",
      "ā ñātisaṅghassa mantaraṃ adassanena asmākaṃ amhākaṃ dukkhaṃ bahūsu tesaṃ sokavi\n",
      "bhāyāmi sumukha sāmāya lakkhaṇūruyā asmākaṃ vadhamaññāya athattānaṃ pākahaṃsā c\n",
      "itāva puttānaṃ bhūtānaṃ dharaṇīriva asmākaṃ adhipannānaṃ khamassu rājakuñjara e\n",
      "nasaṇḍaṃ anuppattā ayuttaṃ kho pana asmākaṃ ayyesu idha vasantesu puttadāre gah\n"
     ]
    }
   ],
   "source": [
    "text.concordance('asmākaṃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1m.xml', 'v2m.xml', 'v3m.xml', 'v4m.xml', 'v5m.xml', 'v6m.xml']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The three 'baskets' of the Buddhist Canon are Vinaya, Sutta, and Abhidhamma\n",
    "\n",
    "# make vinaya text, mūla only\n",
    "vinaya_files=[f for f in os.listdir('..') if f[0] == 'v' and f[-5]=='m']\n",
    "vinaya_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1m.xml 69771 cumulative 0\n",
      "v2m.xml 46150 cumulative 69771\n",
      "v3m.xml 31302 cumulative 115921\n",
      "v4m.xml 100456 cumulative 147223\n",
      "v5m.xml 94064 cumulative 247679\n",
      "v6m.xml 61914 cumulative 341743\n",
      "vinaya tokens 403657\n"
     ]
    }
   ],
   "source": [
    "vinaya_tokens = []\n",
    "for fileid in vinaya_files:\n",
    "    f = open(\"../\" + fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens), 'cumulative', len(vinaya_tokens))\n",
    "    vinaya_tokens.extend(tokens)\n",
    "print('vinaya tokens', len(vinaya_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sutta text, mūla only\n",
    "sutta_files = [f for f in os.listdir() if f[0] in 'dmsak' and f[-5]=='m']\n",
    "sutta_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sutta_tokens = []\n",
    "for fileid in sutta_files:\n",
    "    f = open(fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens))\n",
    "    sutta_tokens.extend(tokens)\n",
    "print('sutta tokens', len(sutta_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(set(sutta_tokens)))\n",
    "sutta_text = nltk.Text(sutta_tokens)\n",
    "sutta_text.collocations()\n",
    "fd = nltk.FreqDist(sutta_text)\n",
    "fd.most_common(50)\n",
    "fd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(fd)\n",
    "len(fd.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make abhidamma text , mūla only\n",
    "abhi_files = [f for f in os.listdir() if f[0] == 'x'  and f[-5]=='m']\n",
    "abhi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abhidhamma_tokens = []\n",
    "for fileid in abhi_files:\n",
    "    f = open(fileid)\n",
    "    raw = f.read()\n",
    "    raw2 = BeautifulSoup(raw, 'lxml').get_text()\n",
    "    tokens = word_tokenize(raw2)\n",
    "    tokens = [t.lower() for t in tokens \n",
    "          if \"^ea^\" not in t \n",
    "          and \"^eb^\" not in t\n",
    "          and t.isalpha()]\n",
    "    print(fileid, len(tokens), 'cumulative', len(abhidhamma_tokens))\n",
    "    abhidhamma_tokens.extend(tokens)\n",
    "print('abhidamma tokens', len(abhidhamma_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's make one file per basket\n",
    "\n",
    "import fileinput\n",
    "\n",
    "def concatenate_files(input_list_of_files, output_filename):\n",
    "    with open(output_filename, 'w') as fout, fileinput.input(input_list_of_files) as fin:\n",
    "        for line in fin:\n",
    "            fout.write(line)\n",
    "\n",
    "concatenate_files(vinaya_files, 'Vinaya_all.xml')\n",
    "concatenate_files(sutta_files, 'Sutta_all.xml')\n",
    "concatenate_files(abhi_files, 'Abhi_all.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('vinaya_all.xml') as pf:\n",
    "    soup = BeautifulSoup(pf, 'xml')\n",
    "    \n",
    "v = nltk.Text(soup.text)\n",
    "cfdv = nltk.FreqDist(v)\n",
    "\n",
    "# letter distribution, note the capital letters are broken out\n",
    "cfdv.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cfdv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v2 = [s.lower() for s in v if s.isalpha()]\n",
    "v3 = ''.join(v2)\n",
    "\n",
    "v4 = nltk.Text(v3)\n",
    "cfdv4 = nltk.FreqDist(v4)\n",
    "\n",
    "# letter distribution, note the capital letters are broken out\n",
    "cfdv4.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def letter_distribution(xmlfile):\n",
    "    with open(xmlfile) as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "    soup = [s.lower() for s in soup.text if s.isalpha()]\n",
    "    print(soup[:100])\n",
    "    soup = ''.join(soup)\n",
    "    soup = nltk.Text(soup)\n",
    "    fd = nltk.FreqDist(soup)\n",
    "    fd.plot()\n",
    "    return fd.most_common()\n",
    "\n",
    "letter_distribution('Vinaya_all.xml')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letter_distribution('Sutta_all.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letter_distribution('Abhi_all.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conditional frequency distribution\n",
    "\n",
    "def soupify(xmlfile):\n",
    "    with open(xmlfile) as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "    soup = [s.lower() for s in soup.text if s.isalpha()]\n",
    "    soup = ''.join(soup)\n",
    "    print(len(soup))\n",
    "    print(soup[:100])\n",
    "    soup = nltk.Text(soup)\n",
    "    return soup\n",
    "\n",
    "soupify('Vinaya_all.xml')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist([s for s in soupify('Vinaya_all.xml')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['Vinaya_all.xml', 'Sutta_all.xml', 'Abhi_all.xml']\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "        (fileid, s) \n",
    "        for fileid in files\n",
    "        for s in soupify(fileid)\n",
    ")\n",
    "cpd = nltk.ConditionalProbDist(cfd, nltk.MLEProbDist)\n",
    "\n",
    "\n",
    "#WAT how come the sutta has such a low total count? \n",
    "#The file sizes would have made me think differently\n",
    "#sutta 32MB, vinaya 16MB, abhi 4 MB ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cpd['Sutta_all.xml'].prob('r'))\n",
    "print(cpd['Vinaya_all.xml'].prob('r'))\n",
    "cpd['Abhi_all.xml'].prob('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd1 = cpd['Sutta_all.xml']\n",
    "fd1 = nltk.FreqDist((s, pd1.prob(s)) for s in pd1.samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd1 = pd1.freqdist()\n",
    "allfds = [cpd[fn].freqdist() for fn in files]\n",
    "fd1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unsorted_list = [(x, allfds[0].freq(x)) for x in allfds[0].keys()]\n",
    "print(unsorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_list = sorted(unsorted_list)\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xlabs, vals = zip(*sorted_list)\n",
    "print(xlabs)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allxlabs, allvals = [], []\n",
    "for fd in allfds:\n",
    "    arr = sorted([(x, fd.freq(x)) for x in fd.keys()])\n",
    "    xlabs, vals = zip(*arr)\n",
    "    allxlabs.append(xlabs)\n",
    "    allvals.append(vals)\n",
    "assert(allxlabs[0]==allxlabs[1] and allxlabs[1]==allxlabs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "nvals = len(allvals[0])\n",
    "plt.plot(range(nvals), allvals[0], label=files[0])\n",
    "plt.plot(range(nvals), allvals[1], label=files[1])\n",
    "plt.plot(range(nvals), allvals[2], label=files[2])\n",
    "plt.xticks(range(nvals), allxlabs[0])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(plt.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sutta = soupify('Sutta_all.xml')\n",
    "len(sutta)\n",
    "''.join(sutta[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(nltk.ConditionalProbDist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
